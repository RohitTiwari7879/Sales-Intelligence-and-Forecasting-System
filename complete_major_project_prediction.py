# -*- coding: utf-8 -*-
"""complete major project prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vY0frkQ_5ooS4X-ySf3LHfL3hOUcRQ3r
"""

# Import important libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.cluster import KMeans

"""**Customer Segmentation (Clustering)**"""

# Load datasets
customers = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/customers.csv', encoding='latin-1')
orders = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/orders.csv', encoding='latin-1')
order_details = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/order_details.csv', encoding='latin-1')
products = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/products.csv', encoding='latin-1')

# Merge datasets
df = orders.merge(order_details, on='orderID', how='left')
df = df.merge(customers, on='customerID', how='left')
df = df.merge(products, on='productID', how='left')

df.info()

df.describe()

# Feature Engineering
df['TotalSpent'] = df['quantity'] * df['unitPrice_x']
df['AverageOrderValue'] = df.groupby('customerID')['TotalSpent'].transform('sum') / df.groupby('customerID')['orderID'].transform('count')
df['NumberOfOrders'] = df.groupby('customerID')['orderID'].transform('count')
df['orderDate'] = pd.to_datetime(df['orderDate'], errors='coerce')
df['OrderFrequency'] = df['NumberOfOrders'] / ((df['orderDate'].max() - df.groupby('customerID')['orderDate'].transform('min')).dt.days + 1)
df['PreferredCategory'] = df.groupby('customerID')['categoryID'].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan)

# Drop duplicates
df = df.drop_duplicates('customerID')

# Encode Preferred Product Category using OneHotEncoder
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
categorical_features = encoder.fit_transform(df[['PreferredCategory']])
categorical_df = pd.DataFrame(categorical_features, columns=encoder.get_feature_names_out(['PreferredCategory']))
df = pd.concat([df, categorical_df], axis=1)

# Select Features
features = ['NumberOfOrders', 'TotalSpent', 'AverageOrderValue', 'OrderFrequency'] + list(categorical_df.columns)
X = df[features]
# Impute missing values before scaling
imputer = SimpleImputer(strategy='mean') # Create an imputer instance
X = imputer.fit_transform(X)

# Standardize the Data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply KMeans Clustering
kmeans = KMeans(n_clusters=4, random_state=42)
df['Cluster'] = kmeans.fit_predict(X_scaled)

# Visualize Clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(x='NumberOfOrders', y='TotalSpent', hue='Cluster', data=df, palette=['red', 'yellow', 'skyblue', 'green'], s=100)
plt.title('Customer Segmentation using K-Means')
plt.xlabel('Number of Orders')
plt.ylabel('Total Spending')
plt.legend(title='Cluster')
plt.show()

# Display cluster means
cluster_means = df.groupby('Cluster')[['NumberOfOrders', 'TotalSpent', 'AverageOrderValue', 'OrderFrequency']].mean()
print('\t\t\t\tCluster Means:\n\n', cluster_means)

plt.figure(figsize=(10, 6))
sns.scatterplot(x='OrderFrequency', y='AverageOrderValue', hue='Cluster', palette='Set2', data=df)
plt.title('Average Order Value vs Order Frequency')
plt.show()

# Plot Total Spent vs Average Order Value
plt.figure(figsize=(10, 6))
sns.scatterplot(x='TotalSpent', y='AverageOrderValue', hue='Cluster', palette='Set3', data=df)
plt.title('Total Spent vs Average Order Value')
plt.show()

# Plot Order Frequency vs Number of Orders
plt.figure(figsize=(10, 6))
sns.scatterplot(x='OrderFrequency', y='NumberOfOrders', hue='Cluster', palette='cool', data=df)
plt.title('Order Frequency vs Number of Orders')
plt.show()

# Pairplot for detailed visual insights
sns.pairplot(df, hue='Cluster', vars=['NumberOfOrders', 'TotalSpent', 'AverageOrderValue', 'OrderFrequency'], palette='Dark2')
plt.show()

"""**Sales Prediction using Linear Regression**"""

# Load datasets
customers = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/customers.csv', encoding='latin-1')
orders = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/orders.csv', encoding='latin-1')
order_details = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/order_details.csv', encoding='latin-1')
products = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/products.csv', encoding='latin-1')

# Merge datasets
df = orders.merge(order_details, on='orderID', how='left')
df = df.merge(customers, on='customerID', how='left')
df = df.merge(products, on='productID', how='left')
print(df)

df.info()

df.describe()

# Feature Engineering
df['TotalSales'] = df['quantity'] * df['unitPrice_x']
df['DiscountPercentage'] = df['discount'] * 100

# Extract time-based features
df['orderDate'] = pd.to_datetime(df['orderDate'], format='%m/%d/%Y', errors='coerce')
df['Year'] = df['orderDate'].dt.year
df['Month'] = df['orderDate'].dt.month
df['Day'] = df['orderDate'].dt.day

# Select Features and Target
features = ['Year', 'Month', 'Day', 'quantity', 'unitPrice_x', 'DiscountPercentage']
target = 'TotalSales'

X = df[features]
y = df[target]

imputer = SimpleImputer(strategy='mean')  # or strategy='median'
X = imputer.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Linear Regression Model
model = LinearRegression()
model.fit(X_train,y_train)

print("Intercept:",model.intercept_)
print("Slope:",model.coef_)
# Predict
y_pred = model.predict(X_test)

# Evaluate Model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'MAE: {mae}')
print(f'MSE: {mse}')
print(f'R2 Score: {r2}')

# Visualize Results
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')
plt.xlabel('Actual Sales')
plt.ylabel('Predicted Sales')
plt.title('Actual vs Predicted Sales')
plt.show()

# resuduals
plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c='b', s=40, alpha=0.5)
plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c='g', s=40)  # Use X_test for green points
plt.hlines(y=0, xmin=0, xmax=50)
plt.title("Residual Plot training (blue) vs test (green)")
plt.ylabel("Residuals")
plt.show()

# User Input for Prediction
print("Enter details to predict sales:")
Year = int(input("Enter year: "))
Month = int(input("Enter month: "))
Day = int(input("Enter day: "))
quantity = float(input("Enter quantity: "))
unitPrice_x = float(input("Enter unit price: "))
DiscountPercentage = float(input("Enter discount: "))

input_data = pd.DataFrame([[Year,Month,Day,quantity, unitPrice_x, DiscountPercentage]], columns=features)

prediction = model.predict(input_data)
print("Predicted sales:", prediction[0])

"""**Customer Churn Prediction using Logistic Regression**"""

# Load datasets
customers = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/customers.csv', encoding='latin-1')
orders = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/orders.csv', encoding='latin-1')
order_details = pd.read_csv('/content/drive/MyDrive/Northwind ml prediction/order_details.csv', encoding='latin-1')

# Merge datasets
df = orders.merge(order_details, on='orderID', how='left')
df = df.merge(customers, on='customerID', how='left')
print(df)

df.info()

df.describe()

# Feature Engineering
df['TotalSpent'] = df['quantity'] * df['unitPrice']
df['orderDate'] = pd.to_datetime(df['orderDate'], format='%m/%d/%Y', errors='coerce')
df['LastOrderDate'] = df.groupby('customerID')['orderDate'].transform('max')
df['TimeSinceLastOrder'] = (df['LastOrderDate'].max() - df['LastOrderDate']).dt.days
df['AverageOrderValue'] = df['TotalSpent'] / df.groupby('customerID')['orderID'].transform('count')
df['NumberOfOrders'] = df.groupby('customerID')['orderID'].transform('count')

# Create Churn Label (1 if no order in last 6 months, 0 otherwise)
df['Churn'] = (df['TimeSinceLastOrder'] > 180).astype(int)

# Drop duplicates and keep customer-level data
df = df.drop_duplicates('customerID')

# Select Features and Target
features = ['NumberOfOrders', 'TimeSinceLastOrder', 'TotalSpent', 'AverageOrderValue']
target = 'Churn'
X = df[features]
y = df[target]
y = y.dropna()  # Drop rows with NaN values in 'Churn'
# Adjust X to match the dropped rows in y
X = X.loc[y.index]

# Impute missing values using SimpleImputer
imputer = SimpleImputer(strategy='mean') # Create an imputer instance
X = imputer.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Logistic Regression Model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate Model
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')
print('Confusion Matrix:\n', confusion_matrix(y_test, y_pred))
print('Classification Report:\n', classification_report(y_test, y_pred))

# Visualize Results
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='RdBu_r')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve
from sklearn.metrics import roc_curve, auc
y_churn_prob = model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_churn_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Churn Prediction')
plt.legend()
plt.show()

# Sample input
print("Enter details to predict churn:")
NumberOfOrders = float(input("Enter Number Of Orders: "))
TimeSinceLastOrder = float(input("Enter Time Since Last Order: "))
TotalSpent = float(input("Enter Total Spent: "))
AverageOrderValue = float(input("Enter Average Order Value: "))

features = ['NumberOfOrders', 'TimeSinceLastOrder', 'TotalSpent', 'AverageOrderValue']
input_data = pd.DataFrame([[NumberOfOrders, TimeSinceLastOrder, TotalSpent, AverageOrderValue]],columns=features)

Prediction = model.predict(input_data)
print("Prediction (1 = Churn, 0 = Not Churn):", Prediction[0])